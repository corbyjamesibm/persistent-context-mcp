# Persistent Context Store Environment Configuration
# Copy this file to .env and configure with your values

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================

# Application Environment
NODE_ENV=production
PORT=3000
LOG_LEVEL=info

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Neo4j Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-secure-password-change-me
NEO4J_DATABASE=contextstore

# Neo4j Ports (for Docker Compose)
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# JWT Secret (MUST be changed in production - minimum 32 characters)
JWT_SECRET=your-very-secure-jwt-secret-minimum-32-characters-long

# Session Secret
SESSION_SECRET=your-secure-session-secret-change-me

# API Rate Limiting
API_RATE_LIMIT=10000

# CORS Configuration
CORS_ORIGIN=http://localhost:3000

# =============================================================================
# AI INTEGRATION
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=2048
OPENAI_TEMPERATURE=0.7

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=2048
ANTHROPIC_TEMPERATURE=0.7

# AI Features
AI_RATE_LIMIT_REQUESTS_PER_MINUTE=30
AI_RATE_LIMIT_REQUESTS_PER_HOUR=500
AI_DAILY_TOKEN_LIMIT=100000
AI_AUTO_ENHANCE_CONTEXTS=false
AI_CACHE_ENABLED=true
AI_CACHE_TTL_SECONDS=3600

# AI Monitoring Webhooks
AI_USAGE_WEBHOOK_URL=https://your-webhook-url.com/ai-usage
AI_ERROR_WEBHOOK_URL=https://your-webhook-url.com/ai-errors

# Legacy LLM Keys (for backward compatibility)
CLAUDE_API_KEY=llm_your_claude_api_key_here
LLM_API_KEY=llm_your_general_llm_key_here

# =============================================================================
# CACHING & SESSION STORAGE
# =============================================================================

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_PORT=6379
CACHE_TTL=3600

# =============================================================================
# MONITORING & HEALTH
# =============================================================================

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30000
PERFORMANCE_MONITORING=true
METRICS_COLLECTION=true

# =============================================================================
# BACKUP & STORAGE
# =============================================================================

# Backup Configuration
BACKUP_DIRECTORY=/var/backups/contextstore
BACKUP_RETENTION_DAYS=90
BACKUP_COMPRESSION=true

# File Storage
UPLOAD_MAX_SIZE=10mb
TEMP_DIRECTORY=/tmp/contextstore

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Feature Toggles
ENABLE_SEMANTIC_SEARCH=true
ENABLE_ANALYTICS=true
ENABLE_BACKUP_AUTOMATION=true
ENABLE_HEALTH_MONITORING=true
ENABLE_RATE_LIMITING=true
ENABLE_AI_INTEGRATION=true
ENABLE_COLLABORATION=true

# Experimental Features
ENABLE_REAL_TIME_COLLABORATION=false
ENABLE_ML_RECOMMENDATIONS=false
ENABLE_VECTOR_SEARCH=false